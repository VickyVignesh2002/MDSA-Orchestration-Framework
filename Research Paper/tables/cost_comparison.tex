\begin{table*}[htbp]
\caption{MDSA Framework Annual Cost Analysis for Enterprise Deployment}
\label{tab:cost}
\centering
\begin{tabular}{|l|c|l|}
\hline
\textbf{Cost Component} & \textbf{Amount/Year} & \textbf{Basis/Notes} \\
\hline
\hline
\multicolumn{3}{|c|}{\textit{Scenario: 10,000 queries/day, 3.65M queries/year}} \\
\hline
\multicolumn{3}{|c|}{\textbf{Local Deployment (Ollama)}} \\
\hline
Infrastructure (CPU) & \$720/year & 8 cores, 16GB RAM (AWS t3.large equivalent) \\
LLM API Costs & \textbf{\$0} & Local Ollama deployment (zero API costs) \\
Storage (Vector DB) & \$120/year & 50GB SSD for ChromaDB \\
Bandwidth & \$80/year & Minimal egress traffic \\
\textbf{Total (Local)} & \textbf{\$920/year} & Full operational cost \\
\hline
\multicolumn{3}{|c|}{\textbf{Cloud Deployment (GPT-3.5-turbo)}} \\
\hline
Infrastructure & \$1,440/year & Managed cloud VM \\
LLM API Costs & \$1,460/year & Average 400 tokens/request \\
 & & (\$0.0015/1K input, \$0.002/1K output) \\
Vector DB (Pinecone) & \$480/year & Managed vector database \\
Bandwidth & \$120/year & Cloud egress fees \\
\textbf{Total (Cloud)} & \textbf{\$3,500/year} & Full operational cost \\
\hline
\multicolumn{3}{|c|}{\textbf{Cost Per Request (Measured)}} \\
\hline
Direct Compute Cost & \textbf{\$0.0006-0.0009} & Measured from 10,000 request test suite \\
Cost per 1,000 queries (Local) & \textbf{\$0.25} & Based on infrastructure cost \\
Cost per 1,000 queries (Cloud) & \$0.96 & Based on infrastructure + API costs \\
\hline
\multicolumn{3}{|c|}{\textbf{Scalability Analysis}} \\
\hline
Break-even Point & 4,200 queries/day & When local deployment equals cloud cost \\
ROI Timeline (Local) & 2 months & Time to recover infrastructure investment \\
Capacity per Node & 8-10 requests/second & Based on 348-391ms median latency \\
\hline
\multicolumn{3}{|c|}{\textbf{5-Year Total Cost of Ownership}} \\
\hline
Local Deployment & \textbf{\$4,600} & 5 years of infrastructure + storage \\
Cloud Deployment & \$17,500 & 5 years of infrastructure + API + storage \\
\textbf{5-Year Savings (Local)} & \textbf{\$12,900} & Cost savings vs cloud deployment \\
\hline
\end{tabular}
\vspace{0.2cm}

\textit{Note: Infrastructure costs based on AWS EC2/equivalent pricing (2024). LLM API costs use GPT-3.5-turbo pricing (\$0.0015/1K tokens input, \$0.002/1K tokens output). Token counts include prompts, context, and responses. Local deployment assumes existing hardware or cloud VMs. Direct compute cost per request (\$0.0006-0.0009) measured from 10,000 request test suite on A100 and RTX 4090 environments.}
\end{table*}
