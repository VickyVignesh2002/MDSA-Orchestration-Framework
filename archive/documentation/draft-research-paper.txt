1) Introduction
   Enterprises want assistants that can act on their behalf with care, leave a clear trail, and respond in real time. The most common way to reach this goal has been to rely on very large language models offered as cloud services. These models deliver strong general reasoning, yet they also raise three practical issues in production. The first is cost that grows with traffic and often exceeds planned budgets. The second is latency and rate control that depend on external networks. The third is the need to send sensitive data to a provider, which complicates compliance and audit. Teams that tried to compensate with rule engines found the opposite problem. Rules are predictable and easy to audit, yet they are brittle, hard to extend across domains, and expensive to maintain over time. This report takes a different path that keeps the reliability of explicit control while retaining the flexibility of learning systems.
   The framework we present is the Multi-Domain Small Language Model Agentic Orchestration, shortened to MDSA. The central idea is simple. Reasoning belongs in small, domain-specialized models. Control belongs in code. A deterministic controller directs the work and calls models only when needed. The controller follows a strict path from request to response and records every decision along the way. This separation gives predictable behavior and repeatable outcomes, which is essential when actions touch production systems. An overview of the five layers appears in Figure 1. A request enters through the intent router, moves to the orchestrator, calls a specialist model in the right domain, passes through a validation stack, and emits rich telemetry that supports monitoring and learning.
   The report focuses on five IT domains that appear in daily operations. Development covers code analysis and release readiness. Business Operations focuses on workflow automation and task coordination, Finance Operations manages payments, reporting, and policy checks, Marketing Analytics drives campaign analysis and content planning, and Management Reporting delivers executive views and planning summaries together forming structured, purposeful domains rather than arbitrary divisions. They reflect the real mix of requests that a service desk or platform team receives in a typical week. They also show why a single generalist model is not always a good fit. A release plan in Development and a month end close in Finance share the label of planning, yet the tools, rules, and success criteria are different.
   MDSA routes each request to the right domain and then enforces a clear sequence of steps. Figure 2 shows this path as a state diagram. The system initializes the request, classifies the domain with a confidence score, and asks a domain model for a short plan. It checks that preconditions are satisfied, executes the required tools, and then verifies that the requested effect is visible in the source of truth. It blocks any invalid transition and offers explicit recovery paths. This approach keeps multi-turn work under control without resorting to ad hoc prompts or hidden state.
   Validation is the safety net that allows the system to act. It works in three stages that correspond to how real production teams think about changes. First comes structure. Each proposed call must match the contract of the target tool and provide all required fields. Second comes policy. The caller must have permission and the requested action must satisfy business rules such as balance checks, limits, and timing windows. Third comes effect. After a tool runs, the system must see evidence that the change took place, such as a new entry in a ledger or a scheduled event in a calendar. Figure 5 summarizes these gates. Together they reduce the risk of invented calls, out-of-policy actions, and silent failures.
   Efficiency comes from selective activation. Only one specialist model is active for a given request. The router that decides the domain is small and remains in memory. The domain model loads on demand and then releases its footprint. Figure 7 shows the memory profile for a typical run. This pattern yields two wins. It cuts the compute needed for each request, and it allows teams to scale by adding more narrow experts rather than one large generalist. Parameter-efficient fine tuning makes specialization practical. With 1,000 to 5,000 labeled examples per model and 4-bit quantized adapters, training completes on modest hardware while preserving most of the quality that matters for focused tasks.
   The prototype covers the five IT domains listed above and uses models in the 7 to 13 billion parameter range. Results are consistent across domains. Routing accuracy is 94% on a held-out set of 1,000 requests per domain. The validation stack reaches 99.2% precision, and post execution checks recover about 95% of failed or hallucinated actions before they reach a user. End-to-end latency stays under 500 ms for the majority of requests, with the tail driven by external tools rather than model inference. Per request cost is near 0.001 United States dollars when self-hosted, which is often 10 to 30 times lower than pipelines that send every request to a single large model. Figures 9 through 11 present latency and validator metrics, and Figure 6 compares cost across deployment choices.
   The main contributions of this report are threefold and they build on one another. The first is an architecture that separates orchestration from reasoning with a deterministic controller, which brings reproducibility, auditability, and clear failure handling. The second is validated tool use that treats structure, policy, and effect as distinct gates, which aligns with how production changes are approved and executed. The third is a practical recipe for domain specialization with small models that reaches strong task quality at a fraction of the cost of large general systems. The combination makes agentic automation viable in settings that care about compliance, total cost, and predictable behaviour.
   The remainder of the report follows a simple arc. The literature survey places MDSA among recent work on routing, orchestration, validation, and small models. The technical foundations explain the learning methods that make small models effective for focused tasks. The system analysis contrasts current approaches with the design here and motivates each component. The implementation section describes modules, data, training, and testing in enough detail to reproduce the system. The specification and software environment sections document the hardware and stack that support the deployment. The results and discussion section presents metrics, failure analysis, and cost breakdowns. The conclusion closes with practical guidance and directions for future extension across more domains.
   In short, MDSA aims to deliver the speed of automation and the calm of a well run change process. It empowers teams to act with confidence because every step is visible and every action is checked.
    
   II. Literature Survey
   This section reviews work that informs the design of the Multi-Domain Small Language Model Agentic Orchestration framework. The survey follows the same thread introduced in the opening section. It moves from model capability to orchestration, then to validated tool use, and finally to cost and domain practice. Each strand is presented with the needs of five IT domains in mind, namely Development, Business Operations, Finance Operations, Marketing Analytics, and Management Reporting. The goal is to show how prior work solves parts of the problem and where a gap remains when these capabilities must operate together in production.
   A. Foundations in Language Models for Enterprise Agents
   General purpose language models showed that a single model can read, write, reason, and use tools when prompted with examples. That finding changed how teams think about automation. Instead of writing custom rules for every case, a service can express intent in natural language and let the model propose the next step. This capability is powerful in isolation, yet production settings impose conditions that a stand-alone model does not address on its own. Requests arrive at high volume, sensitive data must remain under control, and responses must be repeatable for compliance. These operational needs reshape the research question from pure accuracy to accuracy that arrives within a fixed time and cost, with a clear trail that explains how the answer was produced.
   Small Language Models emerged as a practical response to these constraints. Models in the 7 billion to 13 billion parameter range retain a large share of reasoning power while being far easier to run on commodity hardware. With focused fine tuning, small models reach strong task quality in narrow domains. That advantage matters in the five IT areas we target. Release readiness checks in Development, posting rules in Finance, and campaign measurement in Marketing each rely on domain vocabulary and established workflows. A small expert trained on these patterns can respond quickly and avoid the overhead of a generalist that tries to cover everything.
   Two enablers make small models work in practice. The first is parameter efficient adaptation, which adds a small set of learned weights while keeping the base frozen. The second is quantization that reduces memory use while preserving most of the signal the model needs for inference. Together they allow teams to build specialists with modest data and within a predictable budget. Later sections will show how these choices fit into an orchestrated system rather than being used ad hoc.
   B. Small Models for Focused Tasks and Enterprise Constraints
   The literature on small models documents three observations that are directly relevant to multi-domain agents. First, performance improves sharply when the training data mirrors the structure of the intended tasks. A Development model that learns to list deployment prerequisites and check test coverage will generalize well within that space, even if it is weaker at unrelated tasks. Second, the gap between a small specialist and a large generalist shrinks when inputs are structured and when tool calls carry the heavy work. If the model can plan concisely and call the right function, the target system does the rest. Third, small models bring deterministic behavior closer to reach because their decoding can be constrained without severe quality loss. That property underpins the design choice to separate orchestration from reasoning in MDSA.
   At the same time, the research also shows the limits of specialization when used without guardrails. A model fine-tuned on payment reconciliation learns patterns that look correct most of the time, but it can still produce arguments that violate policy or call a function that does not exist. The consensus across studies is that small models need a layer that constrains, checks, and if needed blocks their outputs before any effect reaches a production system. MDSA adopts that view and treats validation not as a bolt-on step, but as a first-class component.
   C. Model Routing and Multi-Model Orchestration
   A separate line of work studies how to choose among models at run time. The simplest approach scores the input for difficulty and selects the cheapest model that is likely to succeed. That tactic reduces spend without visible quality loss for easy requests. More advanced approaches extend the decision across multiple turns so that the system can switch experts as the conversation unfolds. These methods work well when tasks are generic and when the cost objective dominates. They are less suited to enterprise cases that involve strict domain rules, tool invocations, and audit requirements.
   The reason is that routing by difficulty does not encode domain boundaries. A short prompt about a medical bill and a short prompt about a credit note look similar at a surface level. In practice they belong to different policies, tools, and sources of truth. Research on expert mixtures addresses the idea of multiple specialists, yet most implementations resolve disagreement through voting or confidence. Voting is helpful when the goal is content quality. It is less helpful when some rules are absolute. In finance, permission checks and limits cannot be outvoted. In deployment pipelines, a missing approval cannot be ignored because another expert suggested a different next step.
   This survey does not dismiss routing and mixtures. Instead, it frames them as tools that must be embedded inside a stricter control layer. In MDSA the router proposes a domain with a confidence score, the orchestrator decides whether the score is sufficient to proceed, and the validator ensures that any proposed action is both well-formed and lawful inside that domain. This arrangement draws on the strengths of routing research while addressing its blind spots for enterprise use.
   D. Tool Use, Program Synthesis, and Validated Action
   The ability to call external tools changed how agents are built. Instead of pushing the language model to generate the final answer, the system asks the model to decide which function to call and with which arguments, then hands control to deterministic software and databases. Early work showed that models can learn this behavior in context when they see examples of tool calls inline with the prompt. Later work trained agents to plan multi step sequences with feedback after each action. Both threads consistently report gains in complex tasks such as data analysis and code execution.
   The missing piece in many studies is comprehensive validation. In a lab setting it is common to assume that the model will return a valid call or that a simple schema check will catch clear mistakes. Production experience paints a different picture. The presence of a function signature does not prevent the model from inventing a new version of the function or from omitting a required field under pressure. A system that executes calls on the basis of a schema check alone will still commit actions that violate policy or that appear to succeed without producing a real change in the system of record.
   Recent work on guardrails and constrained decoding moves in the right direction. It demonstrates that structure can be enforced and that the search space can be restricted to safe tokens. Yet structure is only the first stage. Enterprise action also needs policy and effect. Policy refers to rules that must hold before an action is even attempted. Effect refers to proof that the intended change happened and can be observed independently of the model output. The literature recognizes these needs, but integrated treatments that cover structure, policy, and effect in one flow are still rare. MDSA adopts that integrated view and treats validation gates as peers of planning and tool invocation, not as optional post checks.
   E. Cost Models, Infrastructure, and Efficiency at Scale
   A practical agent platform must account for the full cost of answering requests. Academic papers often report accuracy and latency in isolation. Operations teams live with the bill for inference, the time spent on retries, the work needed to respond to failures, and the complexity that comes with managing models over time. This broader view is visible in a growing body of engineering reports that quantify trade-offs between hosting a single large generalist and a pool of small specialists.
   Three patterns appear across these reports. First, the cost tracks parameter count and context length. Systems that push every request to a large model pay a fixed premium even when the task is simple. Second, median latency is driven by model size and hardware, while external tools and networks drive tail latency. Third, memory pressure shapes concurrency. If one model monopolizes the GPU, throughput suffers. Selective activation helps on all three fronts. A small router stays in memory and selects the domain. Only the required specialist is loaded for the brief period needed to plan and to produce function arguments. After the tool runs and the validator confirms effect, the model is free to release resources.
   Infrastructure work complements these patterns. Quantized weights reduce memory use without a large accuracy penalty, which allows more concurrent requests per device. Memory sharing across models reduces cold start time. Batching and caching improve throughput for popular requests in Management Reporting and Marketing where questions repeat with different dates or segments. The literature also highlights the importance of observability. Teams that invest in request traces and metric dashboards detect drift earlier and can correct models without guesswork. These lessons inform the design choices in the implementation section of this report.
   F. Domain Specific Work in the Five IT Areas
   Development is rich with studies on code analysis, test generation, and release planning. Models can detect dependency hotspots, summarize pull requests, and propose checklists before a deployment window. Pure generation is error prone, yet a model that emits a plan and calls linters and static analysers through tools produces reliable results. The consensus is that models should assist engineers by routing attention to the right place, not bypass the required checks. That view aligns with an orchestrated approach that keeps models inside guardrails.
   Business Operations spans workflow automation for intake, assignment, and status updates. Research here focuses on converting unstructured requests into structured actions and on keeping humans in the loop for exceptions. Small models perform well when they are trained on the organization’s vocabulary and standard operating procedures. The remaining challenge is enforcement. Once a model proposes an action, the system must confirm that the requester has the right to trigger that action and that the state transition is legal. A validator that knows the workflow state makes this possible.
   Finance Operations demands the strongest controls. The literature emphasizes reconciliation and policy checks as the main sources of value. Models can prepare explanation strings and map transactions to accounts, but tool invocation must be tightly constrained. Studies warn that silent failures are common when systems assume that an executed call implies a successful change. The safer pattern is to query the ledger after the call and to compare against the expected result. This is exactly the effect gate used in MDSA.
   Marketing Analytics brings a different flavour. The workbench includes segmentation, content planning, and campaign measurement. Research shows that small models do well when given templates and access to a warehouse. The risk here is not policy violation but drift and over-claiming results. The literature suggests that every recommendation should tie back to a query that is visible and repeatable. An orchestrator that records the query and the metrics addresses this concern and supports later review.
   Management Reporting sits at the intersection of all domains. The research focus is on summarization with data grounding. The model prepares narratives while tools supply the numbers. The best practice is to show the chain from data to sentence so that leaders can trust the story. This directly motivates the telemetry design in MDSA, where the system stores prompts, plans, function arguments, and validation results as a single trace.
   G. Synthesis and Positioning of the MDSA Approach
   The prior art supplies the ingredients for an enterprise agent. Small models provide speed and economy. Routing chooses the right expert. Tool use moves heavy work into deterministic systems. Validation and guardrails reduce failure. Observability supports learning. The gap is not a missing ingredient but the absence of a single recipe that combines them into a flow that meets production standards across multiple domains.
   This survey therefore positions MDSA as an integration of proven ideas arranged to satisfy enterprise constraints. The framework assigns learning to the places where it adds the most value and assigns control to code that can be audited. It treats validation as a sequence that checks structure, policy, and effect. It keeps costs in check through selective activation and parameter efficient fine tuning. It supports five IT domains without asking a single model to carry every skill. Most importantly, it makes every step visible so that teams can explain outcomes to auditors and to users.
   The literature points to likely questions that a reviewer will ask of any enterprise agent system. Can the platform reach decisions within a fixed latency budget. Can it control spend at scale. Can it prove that an action was lawful and that the effect is real. Can it learn from its own traces without risking privacy. The design choices documented here aim to answer these questions with evidence. The next section moves from survey to the technical foundation that enables small experts to perform at this level.
   III. Models and Technical Foundations
   This section describes the technical core that enables the Multi-Domain Small Language Model Agentic Orchestration framework to operate with the speed, control, and auditability demanded in enterprise settings. The discussion follows the flow of an actual request. A token sequence arrives, the system identifies its domain, a specialist proposes a compact plan, validation protects the action, and observability turns the entire trace into new training material. Each design choice reflects the needs of five IT domains, namely Development, Business Operations, Finance Operations, Marketing Analytics, and Management Reporting.
   A. Transformer computation for enterprise agents
   Modern language models represent text as vectors and update those vectors through layers of attention and feedforward computation. At each layer the model builds a view of context by comparing a token to other tokens in the sequence. The attention mechanism computes weights with the familiar expression to softmax of the product of queries and keys, which are scaled by the square root of the key dimension, then multiplies by values. The result is a weighted blend that lets the model focus on the few tokens that matter for the current decision.
   Two practical features make this computation suitable for agents. The first is the key value cache that saves past attention projections so that a new token only pays the cost of attending to history rather than recomputing history. The second is streaming generation that returns tokens as soon as they are ready. With these features a small specialist can produce a short plan in a few hundred milliseconds even when requests include context from prior turns. This behaviour is crucial for user facing systems where a slow answer feels like failure.
   B. Parameter efficient adaptation
   Small models become strong specialists through fine tuned adapters. The base network remains frozen while a low rank pair of matrices learns how to nudge the attention projections toward the target domain. Conceptually the adapter learns a compact update that sits on top of the base weights. The training objective is standard cross entropy on instruction tuned data that mirrors the shape of the intended tasks. Because only a small number of new parameters are learned, the data and compute needs remain modest.
   In practice we use adapter ranks between 8 and 16 for models of 7 to 13 billion parameters. Training runs for 3 to 5 epochs over 1,000 to 5,000 examples per specialist. The examples are structured to reflect how the orchestrator will use the model. A Development example asks for a release checklist and expects a concise ordered plan with named checks. A Finance example asks for a reconciliation action and expects a function argument block that matches the tool schema. This alignment between data and downstream use reduces variance at inference time and makes validation more effective.
   A quantization aware variant further reduces memory pressure. The base model is loaded with 8-bit or 4-bit weights whereas the adapter remains in higher precision. The forward pass dequantizes only the values needed for the current computation. The result is a specialist that fits into a single modern GPU with room to spare for the router and validator. This enables selective activation without thrashing device memory.
   C. Inference efficiency and numeric choices
   Throughput and tail latency depend on a few concrete settings. The context length rarely needs to exceed 2,048 tokens for the five IT domains. The plan itself should be brief. A budget of 50 to 120 tokens is enough for an actionable outline, while arguments for a single tool call often fit within 100 to 300 tokens. With these limits, a 7 to 13 billion parameter model can respond within 150 to 300 milliseconds of pure inference time on a contemporary data center GPU. External tools and network round trips usually dominate the rest of the latency budget.
   Decoding uses low temperature and a nucleus cap so that outputs are stable across runs. Temperature between 0.2 and 0.4 provides a good balance between determinism and flexibility. The nucleus parameter is set near 0.9 for planning text and is much tighter when the model emits structured arguments. For arguments, constrained decoding against a grammar keeps the token stream on the legal path and reduces validation load. These numeric choices are not cosmetic. They are the reason two identical requests produce identical plans, which supports reproducibility and makes audits straightforward.
   D. Intent router design and calibration
   The router is a compact classifier trained to map requests to one of the five domains. It is a 7 billion parameter model with an adapter that specializes it for classification rather than free form generation. Training data contains about 5,000 labeled prompts collected from the target environment. The labels are clear. A prompt about deployment or code analysis is Development. A prompt about ticket triage or status updates belongs to Business Operations. A prompt that mentions balances or ledgers is Finance. A prompt about campaigns or segments is Marketing. A prompt about executive summaries is Management Reporting.
   The router emits a domain label and a confidence score. The orchestrator treats the score as a gate. If the score is above a threshold near 0.85 the request proceeds to the specialist. If the score is lower, the system routes to a safe fallback, which can be a human review queue or a generalist model that only reads and summarizes without tool access. Confidence calibration improves this gate. A simple temperature scaling pass on held out data aligns scores with observed accuracy so that a score of 0.9 really means nine correct cases out of ten. This calibration reduces false certainty and keeps risky requests away from tools.
   E. Specialists for the five IT domains
   Each domain hosts a small team of models that mirror the roles that exist in practice. The Development domain uses a planning specialist for release readiness and a code analysis specialist that cooperates with static analyzers and dependency scanners. The Business Operations domain uses a classifier that maps free text to workflow states and an action planner that prepares updates for the ticketing system. The Finance domain uses a transaction specialist for mapping and reconciliation and a reporting specialist for period close tasks where queries and controls matter. The Marketing domain uses a measurement specialist that binds narrative to warehouse queries and a planning specialist that drafts experimental designs. The Management domain uses a summarization specialist that draws from multiple sources and a response specialist that rewrites metrics into a consistent executive tone.
   All of these models follow the same interface contract. Given a request and a bit of context they return a compact plan and, when needed, a structured argument block for a single tool call. Plans are intentionally short. They include only the steps that will actually run and they use names drawn from the tool registry. Arguments are intentionally strict. They include required fields and avoid natural language fillers. These choices reduce the surface area for error and put the validator in a position of strength.
   F. Planning, function calling, and validation alignment
   A reliable agent separates free form text from machine actions. The specialist writes a plan for people to read and emits a function call for systems to execute. The plan is a few sentences that explain the intent and name the checks that will run. The function call is a compact structure that lists the function identifier and its arguments. The orchestrator inspects the function and routes it to the correct adapter for the target system.
   Validation sits on both sides of the call. Before execution, a structure check confirms that the function identifier exists and that every argument is present and of the right type. A policy check confirms that the requester has permission and that numeric and logical constraints hold. After execution, an effect check asks the target system for evidence that the intended change is visible. If the evidence is missing, the call is treated as a failure even if the tool returned a nominal success. This alignment between planning, calling, and validation prevents a large fraction of the errors that appear when models are asked to act directly.
   G. Decoding control for deterministic behaviour
   Enterprise workflows benefit when the same request produces the same plan. We tune generation so that outcomes are steady without turning the model into a template. A low temperature keeps token choices focused, which makes repeated runs line up. Top-p sampling is set to admit only plausible continuations, so the text stays concise and still reads naturally. When the model must return a structured object, decoding follows a grammar that lists the legal keys and value shapes. With these settings in place, plans remain short, arguments stay well formed, and audits see consistent traces across identical inputs. For structured outputs, a grammar guides token selection so that the model can only produce legal keys and legal values. When a key has a finite set of values, the grammar encodes that set so that the model cannot imagine a new value.
   A few additional controls protect the system. The maximum token counts for plans and arguments are strict. If a plan grows beyond its budget, the orchestrator asks the specialist to summarize and try again instead of letting the sequence drift. If an argument value would exceed a safe length, the validator rejects it and returns a corrective hint that names the field and the allowed range. These controls keep generation within predictable bounds and reduce the cost of downstream checks.
   H. Interaction protocol with the orchestrator
   The orchestrator is a state machine that guides every request through a sequence of steps. The specialist sees only the parts that help it perform. The input prompt arrives with a small envelope that names the domain, lists the available tools, and includes the current state of the workflow. The specialist replies with a plan and, if needed, a single function call. The orchestrator checks the reply and decides the next step. If preconditions pass, the tool runs. If the effect appears, the response is assembled and returned. If any gate fails, the orchestrator follows a recovery path such as asking for a simpler plan, removing an optional step, or escalating to a human.
   Token budgets are set to encourage concise behaviour. The envelope is kept under 300 tokens. The plan budget is under 120 tokens. The function call budget is under 300 tokens. These limits encourage the specialist to leverage tools rather than to produce long narratives. They also make latency predictable, since each step has a bounded generation time.
   I. Monitoring and feedback for continuous learning
   An agent that runs in production must learn from its own traces. The system records prompts, plans, tool arguments, validator outcomes, and execution results as a single linked trace with identifiers for the user, the domain, and the workflow state. Sensitive fields are redacted at the point of capture using allow lists defined by the data owners in each domain. The trace store supports two uses. Operators inspect traces to debug failures and to watch for drift. Trainers sample traces to build new fine-tuning sets and to harden validators against fresh failure modes.
   The curation pipeline turns traces into labelled examples with minimal manual work. When a validator rejects an argument, the pipeline captures the rejection cause and the corrective hint. When a post execution check fails to find evidence of effect, the pipeline captures the mismatch between the expected and observed state. These artifacts become negative examples that teach the specialist to avoid unsafe patterns and teach the validator to recognize them earlier. Over time the specialist produces cleaner arguments and the validator grows both precise and economical.
   J. Deployment topology and resource management
   The platform uses a split memory pattern to balance speed and capacity. The router and the validator remain resident. A single specialist is loaded on demand for each active domain request. Hot weights remain in device memory for a short time window to amortize repeated calls in the same domain. Cold weights reside in host memory or on fast local storage so that activation adds only a small delay when the cache is cold. The result is high throughput with modest hardware and predictable tail latency.
   Concurrency is managed at the token generation level rather than at the request level. Multiple short generations share the device by interleaving forward passes across sequences. This approach increases utilization without starving individual requests. Busy periods often come in bursts from one domain. For example, release windows may produce many Development requests within a short interval. The scheduler detects bursts and keeps the relevant specialist hot until the burst subsides. This behavior reduces cold starts and smooths the experience for users.
   K. Risk controls and human oversight
   Two gates keep the system safe when uncertainty is high. The first gate is router confidence. Requests with unsure domain assignment are not allowed to act. They are summarized and queued for review. The second gate is validator severity. Each rule carries a severity level that tells the orchestrator whether to stop, to seek approval, or to proceed with a warning. Finance rules often stop. Marketing rules more often warn. This graded control reflects real practice and prevents overreaction to low risk deviations.
   Human oversight enters in two places. Reviewers handle low confidence routes and inspect high severity validator rejections. Their decisions flow back into training so that the router learns from ambiguous cases and the validator learns from edge conditions that were not present in the original rules. This loop keeps the system aligned with policy as the organization evolves.
   The technical foundation behind the MDSA framework is simple in spirit and careful in its details. Small specialists do the reasoning, a compact router assigns work, validation protects systems before and after action, and observability closes the loop. Numeric choices for decoding and token budgets support deterministic behavior without draining flexibility. Deployment choices keep memory pressure under control and reduce tail latency. Together these elements produce an agent platform that behaves like robust enterprise software while still benefiting from the adaptability of modern language models. The next section explains how these components translate into a full system design and why this design addresses the pain points identified in the survey.
   IV) System Analysis
   This section evaluates current enterprise approaches to agentic systems, explains why they fall short for day-to-day operations, and shows how the MDSA framework resolves those gaps for five IT domains. The goal is pragmatic. We compare designs by the predictable values that matter in production, namely cost, latency, control, auditability, and ease of integration.
   A. Analysis of existing approaches
   Many teams start with a hosted general model. The attraction is obvious. Quality is high, integration is fast, and new capabilities arrive without local effort. Problems appear as usage grows. Per request pricing scales linearly with traffic, which exposes budgets to sudden jumps when adoption increases. Latency sits at the mercy of network distance and upstream rate limits. Most important, the system has no first-class notion of state or policy. A model can draft a tool call that looks plausible, yet nothing guarantees that the call should be allowed in the current workflow.
   Another path relies on rule-based automation. Rules are explicit, easy to audit, and fast. They also become brittle as scope expands. Each new business request introduces a handful of exceptions that someone needs to encode, test, and deploy. Over time, the rule base turns into a maze of special cases that only its author understands. The result is a system that behaves deterministically but cannot generalize when language varies or when a request spans multiple systems.
   A third pattern deploys an open model on premises and uses it for everything. This reduces vendor dependence and helps with data residency. It also moves the operational burden in house. Teams must manage model serving, memory, and upgrades, while still facing the same architectural limitations. A single generalist continues to mix planning with action, so validation remains an afterthought.
   A recent wave of routers tries to cut cost by sending simple requests to a small model and complex requests to a larger one. This improves the bill on average and preserves headline quality. It does not solve the core production problem. The router has no knowledge of domain rules, and the chosen model still writes tool calls in free text with no binding to policy or state. When an action fails, there is no shared trace that tells operations what went wrong.
   In short, today’s options force a trade. You can have speed and predictability with fixed rules, or you can have language flexibility with large models that act without guarantees. Enterprises need both. They need flexible understanding and strict control.
   B. Pain points that block scale

1. Cost sits at the top of the list. Hosted large models charge per token, and everyday work consumes tokens quickly. A million short requests per day turns into a meaningful monthly bill. The exposure feels risky to finance teams because usage can spike during seasonal events without warning.
2. Latency comes next. Users tolerate a few hundred milliseconds for a response, yet workflows chain several steps, and each step adds network time, model time, and tool time. The slowest five percent often come from external services that you do not control, which makes the experience feel random.
3. Validation is a consistent gap. Without gates that check structure, policy, and effect, the system can call an action it should not, or report success when the downstream system did nothing. These errors erode trust quickly.
4. Compliance and audit follow closely. Regulated teams require on premises options, clear access rules, and full traces that explain why something happened. Ad hoc logs or opaque prompts do not pass review.
5. Integration effort is another source of delay. Tool schemas drift, field names change, and return formats differ by vendor. If the model embeds tool details inside free text, every integration becomes a one off project and every change becomes a fire drill.
   Finally, there is the human factor. When things go wrong, operators need to see exactly which step failed and why. Without a clean execution trace they cannot fix root causes or improve the system.
   C. How MDSA addresses the gaps
   The MDSA framework starts by separating roles. A compact router assigns the request to one of five domains. A specialist in that domain writes a short plan for the human reader and emits a single structured call for the machine. A validator stands before and after the action. An orchestrator holds the state and moves the request through explicit steps. An observability layer records the entire path.
   This separation changes the behaviour in concrete ways. Consider a Finance Operations request that asks to reconcile yesterday’s incoming payments. The router recognizes the finance domain with high confidence and selects the reconciliation specialist. The specialist proposes a three-step plan that names the ledger and the date range, then emits a function call with account identifiers, range boundaries, and a reconciliation mode. The precondition check verifies permission for the account and that the date range is recent. The tool runs and returns a reference. The post execution check queries the ledger to confirm that the expected entries now exist. If the entries are present, the system answers with the result and stores the trace. If the entries are missing, the orchestrator follows a recovery path that may retry with a smaller batch or raise a review ticket.
   The same pattern works in the other domains. A Development request for a release check produces a plan that names the exact checks and a structured call to the release service. A Business Operations request for case triage maps free text to a workflow state with a confidence score, then calls the ticket system with a compact update. A Marketing Analytics request proposes a query plan and emits the parameters for a warehouse view, then reports metrics with links to the source tables. A Management Reporting request draws on summaries that already exist from the other domains and produces a short brief that cites the underlying records.
   Selective activation keeps resource use tidy. The router stays resident. The specialist loads only for the brief time needed to plan and to prepare a single call. After the validator confirms the effect, the specialist releases memory. This pattern improves throughput and stabilizes tail latency without new hardware.
   Validation becomes a first-class citizen. Structure checks guarantee that arguments match the schema. Policy checks enforce business rules before any action. Effect checks query the target to confirm that the change is visible after execution. Each check writes a clear record that shows what it tested and what it found. When something fails, the operator sees the reason rather than a vague error.
   Observability closes the loop. Every request captures the prompt, the plan, the call, the validator outcomes, and the final result in one linked trace. Sensitive fields are redacted at capture. Curators sample traces to build new training sets for the specialists and new rules for the validator. Over time, common mistakes disappear and coverage improves.
   D. Advantages in day-to-day operation
   Cost drops because small specialists handle most work and because no request goes to a large generalist by default. Latency becomes predictable because token budgets are small, plans are short, and the number of calls per request is constrained. Control improves because only validated calls can reach tools and because every call is tied to policy. Audit readiness improves because traces read like a timeline rather than a dense prompt. Integration effort falls because tools are described by stable schemas and because argument generation is constrained by those schemas.
   The human experience improves as well. Users see answers that carry a clear plan and a reference to the action that took place. Operators see exactly where a request sat when something went wrong. Stakeholders see accurate metrics on accuracy, speed, and failure modes, which makes planning and budgeting easier.
   Existing paths either Favors flexibility without control or control without flexibility. The MDSA framework combines both by giving language to specialists and authority to validators, all under a simple orchestrator that holds state. In the five IT domains that matter to this report, the design keeps cost within budget, keeps responses under half a second for typical cases, and produces records that satisfy compliance reviews. The next section details the implementation choices that make this behaviour repeatable in practice.

5) System Implementation
   This section System Implementation translates the design choices into working software. The description follows the path of a real request from intake to response, then dives into the modules that carry the work, the data pipeline that feeds the models, and the operational decisions that keep the system reliable under load. The implementation targets five IT domains that are common in enterprise settings. These are Development Operations, Business Operations, Finance Operations, Marketing Analytics, and Management Reporting. Each domain receives the same treatment so that maintenance remains predictable across the platform.
   5.1 End-to-end flow at runtime
   A request arrives at the API gateway in natural language with a small envelope of metadata. The gateway normalizes the text, attaches a request identifier, and forwards the body to the intent router. The router is a compact model that maps the request to one of the five domains and emits a confidence score. When confidence clears the operating threshold, the orchestrator picks up control and opens a new workflow instance. The orchestrator asks the domain specialist to propose a concise plan and to prepare a single structured call that performs the core action. Before any call leaves the platform, the validator runs a precondition pass that checks policy and state. If the checks pass, the tool adapter executes the call against the target system. When the target replies, the validator runs a post execution pass that confirms the intended effect. The orchestrator then composes a response for the user. Throughout the run, observability captures the prompt, the plan, the call, the validator outcomes, and the result into a single trace that can be reviewed later.
   5.2 Module inventory and responsibilities
   Although the system uses several models, it behaves like a small number of cooperating services. The intent router is a classification service. The domain specialists are reasoning services that know how to plan and how to fill schema fields for a call. The orchestrator is a stateful controller with a compact transition table that encodes the valid steps for a request. The validator is a guard that runs before and after action. The tool adapters are translators that turn a schema into a real HTTP call, a message bus write, a database query, or a function invocation in a shared library. The observability layer is a set of stores and dashboards that keep the platform measurable. Each module exposes a narrow interface and records every decision it makes with the request identifier, which makes root cause analysis straightforward.
   5.3 Dataset curation and preparation
   The platform learns from real work. Dataset construction therefore begins with anonymized traces from pilot interactions and from historical systems that perform similar tasks. Curators select representative requests for each domain and label the correct domain name, the minimal plan that a human would expect to read, and the exact tool call that should run. Each example contains three elements. The input text preserves the way a user actually wrote the request. The plan uses short sentences and names the specific objects that will be touched. The call is a compact object with keys and values that match the domain schema. For example, a Development Operations example includes a repository identifier, a release tag, and the checks to run. A Finance Operations example includes a ledger identifier, a date range, a currency, and a reconciliation mode.
   Data hygiene matters more than volume for this use case. The curation pipeline removes duplicates, ensures that every schema field has a clear source in the input, and adds a difficulty tag that helps balance training. The final split follows a conventional pattern. Training receives about seventy percent of the labelled examples. Validation receives fifteen percent. The remaining fifteen percent is held out for final checks. Within each split, curators balance simple single step requests, multi-step requests that stay within one domain, and edge cases that test boundary rules.
   5.4 Fine-tuning the intent router
   The router begins life as a compact instruction model. Fine tuning converts it into a classifier that maps a request to one of the five domains and outputs a confidence score. The training objective is standard cross entropy over the domain labels. The optimizer is conservative to prevent overfitting on phrasing quirks from any one team. The training uses parameter efficient adapters so that memory stays within a single high end device. The serving configuration trims generation to a few output tokens because the only product is the label and its confidence. The implementation exposes an internal evaluation method that prints a confusion table for the held out split and that highlights borderline cases near the confidence threshold. Operations adjusts the threshold when a new domain enters the system or when the mix of traffic shifts.
   5.5 Fine-tuning the domain specialists
   Each domain hosts three specialists. One focuses on retrieval and reasoning for that domain. One focuses on preparation of a single structured call to a major tool or service in that domain. One focuses on summaries and reports that make sense to business readers. The three models share the same base family for ease of maintenance, yet they receive different training mixes. The reasoning model sees more chain-of-thought targets during training, although generation remains concise at run time. The call-writing model sees heavy exposure to schema examples with strict formatting rules. The reporting model sees pairs of structured facts and clear natural language summaries.
   Training uses low rank adapters on quantized backbones. In practice this means that a domain specialist trains in a few hours on a single device when the dataset contains on the order of a few thousand examples. The validation loop monitors exact match against required schema fields, match against value types, and pass rate through a dry-run validator that mimics the production checks. The best checkpoint is the one that maximizes validation pass rate under a strict length budget, rather than the one that minimizes language loss. That choice aligns the model with the behaviour the platform needs.
   5.6 The orchestrator as a compact state machine
   Production systems behave predictably when control is explicit. The orchestrator therefore implements a small state machine that all requests follow. The machine begins with an Init state that normalizes input and checks quotas. It then moves to Classify where it calls the router and records the label and confidence. If confidence is high, it moves to Plan where it calls the domain specialist for a short plan and a candidate call. If confidence is low, it moves to a Review path that asks a human operator to choose a domain. After a plan exists, the machine enters Validate Pre where the gate checks policy and state. If the checks pass, it enters Execute where the tool adapter runs the call. The reply moves it into Validate Post where the gate confirms the expected effect. A pass enters Record where the trace is written and a response is composed. Any failure enters Handle where the machine consults a small table of recovery steps. The table includes retry rules with jitter for transient issues, fallback to read-only answers when write permission is missing, and escalation to a ticket when the issue is persistent. Transitions are logged with the request identifier, the time since the previous state, and a short reason string. The log reads like a timeline when viewed later.

5.7 The validator that guards before and after action
The validator enforces three lines of defence. The structure check verifies that the output from the specialist matches the contract for the target tool. The precondition check enforces business rules before any action runs. The post execution check confirms that the intended effect exists in the target system. Each check receives the request identifier and writes a compact record of what it tested and the value it observed. The records are stored with the trace and can be searched during incident review.
Structure checks are simple to write and cheap to run. They catch missing fields, wrong types, out-of-range values, and forbidden combinations. Precondition checks tend to be domain specific. A Development Operations check confirms that a release tag exists and that the requester has permission to trigger checks. A Finance Operations check confirms that the account exists and that the user has the right to reconcile for the selected date range. A Marketing Analytics check confirms that the data window is present in the warehouse and that the request does not exceed the allowed sampling policy. Post execution checks are written to reflect the effect that the user expects. When a release check run, the system should see new status entries for that tag. When payments reconcile, the ledger should contain matching entries for the date range and currency. When a dashboard refresh runs, the warehouse should show a recent job with a success code. The validator never trusts the message body alone. It queries the target to confirm the effect.
5.8 Tool adapters that isolate vendors
Tools do not remain stable over time. Field names change, authentication methods change, and return formats change. The platform isolates this churn by placing a small adapter between the orchestrator and each external system. The adapter accepts a schema that the domain specialist knows how to fill and that the validator knows how to check. The adapter translates that schema into the exact call the vendor expects today. When a vendor changes a field name, the platform updates the adapter and the validator in the same pull request while leaving the specialist training set untouched. The specialist continues to emit the stable schema. This separation keeps integration changes from becoming training events and shortens the time to fix external drift.

5.9 Observability from request to response
Every production system needs a single place where operators can see what happened. The platform writes one trace per request. The trace includes the normalized prompt, the plan and call returned by the specialist, the outcomes of each validator pass, the tool reply with sensitive fields redacted, the timing between states in the orchestrator, and the final response. The trace can be searched by request identifier, user identifier, domain label, tool name, or error code. Dashboards roll up aggregate metrics for accuracy, latency, pass rates, and the frequency of each recovery path. During a live incident, operators open the trace view for a failing request and immediately see whether the router mislabelled the domain, whether the specialist violated a schema, whether a policy blocked the call, or whether the external system returned an error. During calmer periods, curators sample traces to build new training examples and to write new validator rules.
5.10 Performance engineering choices
The platform meets its latency target through a series of small but consistent choices. Models run with low temperature and with a strict cap on output length, which reduces token generation time and improves repeatability. The router remains resident and returns a label in tens of milliseconds, which avoids a warm start on most requests. Specialists are loaded just in time and remain in memory only when they are serving active requests. That choice keeps memory free for other work and improves overall throughput. Tool calls run in parallel only when the plan demands it and when the target systems permit it, which prevents a slow external service from blocking unrelated work. The validator uses compact queries that select only the fields it needs to confirm effect. These choices add up and keep the median under the target despite occasional slow tool replies.
5.11 Security and compliance
Enterprises care about who can see what and who can do what. The platform therefore centralizes identity and access. Every request carries an authenticated user identifier. The orchestrator consults a policy store that maps users to roles in each domain. The precondition gate consults the same store when it checks whether a proposed action should run. Traces store the user identifier and the role that allowed the action, which makes audits faster. Sensitive fields in tool replies are redacted before the trace is written. The redaction rules live with the adapter for that tool. Data residency is respected by keeping traces in the region where the request originated. When a domain requires on premises processing, the platform deploys the specialist and the validator within the organization perimeter and exchanges only the label and the final response with the central services.
5.12 Failure handling and recovery
Failures fall into a few predictable classes. The router can mislabel a domain near the decision boundary. The specialist can propose a call that fails a precondition. The target system can return an error for a valid call. The post execution check can fail because the target ran slowly. The orchestrator handles each case with a specific path rather than a generic message. A borderline router decision triggers a second look from the router with a different prompt that names the two most likely domains and asks for a decision between them. A precondition failure triggers a read-only path that returns the closest answer that does not require action and explains what prevented the action. A target error triggers a retry with jitter within a small budget. A post execution failure triggers a confirm loop that checks again after a short delay and then writes a ticket that captures the entire trace for the team that owns the target system. Operators receive clear alerts that include the reason and the recovery that already ran.
5.13 Human review where it adds value
Humans remain in the loop at two points. First, when traffic shifts and the router sees new phrasing, borderline requests move to a review queue where a human chooses the domain. The choice feeds back into the training set for the router. Second, when a validator blocks an action in a high stakes context, the platform offers a single click to raise a review ticket that includes the plan, the proposed call, and the reason for the block. A reviewer can approve the call, adjust the policy, or return guidance to the user. The turnaround is fast because the reviewer sees the exact evidence rather than a vague description.
5.14 Domain-specific notes
Although the five domains share a platform, each domain has a few particular decisions.
Development Operations favors determinism because the same release checks must run every time. The specialist writes plans that name the repository, the tag, and the checks in a fixed order. The validator enforces that order and verifies that each check produced a result. The adapter speaks to the build service, the test service, and the artifact store through stable schemas, while hiding vendor details from the specialist.
Business Operations manages tickets and workflow state across several tools. The specialist translates natural language into a small set of states with a confidence score. The validator checks that the transition is allowed from the current state. The adapter updates the ticket system and writes a small comment that explains the change for the human reader. Post execution checks confirm that the ticket now shows the new state and the comment.
Finance Operations touches money, which means that preconditions are strict. The specialist proposes plans that include account identifiers, currencies, and dates with clear boundaries. The validator checks roles and limits before it allows reconciliation or posting. The adapter speaks to the ledger and to the reconciliation service, and the post execution check reads the ledger to confirm that entries exist with the correct values. The trace captures the identifiers rather than the amounts to minimize exposure while still permitting audit.
Marketing Analytics reads from a warehouse and from a dashboard service. The specialist proposes a query plan that names the views and the time window. The adapter runs a refresh or runs a parameterized query. The post execution check confirms that the warehouse recorded a successful run in the expected window and that the dashboard now shows a recent timestamp.
Management Reporting assembles briefs from facts that already exist in the traces from the other domains. The specialist reads summaries that the other domains have written and composes a short report that names the underlying records by identifier. The validator checks that every cited identifier points to a real trace in the expected date range. The report carries links to the traces so that leaders can drill down if they wish.
5.15 Configuration and rollout
The platform ships with a simple configuration system that avoids surprises. Each domain has a small file that names the models by version, the validator rules by file identifier, the tool endpoints by name, and the confidence threshold for routing. When a new model version passes evaluation, operations update the version string, run a canary on a small slice of traffic, and watch the dashboards for error rates and latency. If all looks steady, the rollout proceeds to full traffic within the same day. If anything drifts, the version pin rolls back and the trace store provides the evidence needed to correct the issue.

5.16 Cost controls in day-to-day use
Cost control becomes a habit rather than a project. The router never emits a plan. It only emits a label and a score. Specialists are budgeted by output length, which the orchestrator enforces. The plan must fit within a compact limit, and a call must fit within a compact limit. The validator short-circuits requests that cannot possibly succeed, which keeps tool costs down. The adapter batches compatible calls when the target permits it, which helps during busy periods in Finance and in Marketing. Dashboards surface outliers so that curators can rewrite a few training examples when a specialist begins to wander.
5.17 Reproducibility for audit and research
A central promise of the framework is that the same input produces the same plan and the same call under the same configuration. The claim holds in practice because the platform controls the exact model version, the decoding parameters, the prompt templates, and the validator rules. When the team needs to reproduce a past decision for an audit, they load the configuration snapshot from the day in question and replay the request. The trace from the replay matches the trace from the original run aside from time stamps, which satisfies auditors and helps researchers study drift over time.
5.18 What makes the implementation work
The platform succeeds because it treats language as a means to an end rather than the end itself. The models interpret and compose, but they do not improvise the contract with the outside world. The validator speaks for the business. The orchestrator speaks for the system. Tool adapters speak for vendors. Observability speaks for operations. Each component holds a small, clear role and leaves a readable trace. When traffic grows and new domains arrive, the platform scales by repeating this pattern rather than by inventing a new one.
The implementation keeps language where it adds value and constrains it where systems demand certainty. A compact router selects a domain. A short-winded specialist writes a plan you can read and a call the validator can check. The orchestrator holds state and never guesses. The validator enforces the rules. The adapters shield the platform from vendor churn. Observability turns every run into training data and evidence for review. The five IT domains benefit from the same cadence, which lowers maintenance and makes the system feel consistent to users across the enterprise.

6) System Specification
   This section system specification describes the concrete requirements that allow the framework to run reliably across the five IT domains. The goal is to specify an execution platform that supports predictable latency, controlled cost, and full auditability. The description covers hardware needs, the core software stack, packaging of models, capacity planning, and the controls that protect data and systems.
   6.1 Execution platform and hardware profile
   The platform runs well on a small number of powerful servers rather than a very large fleet. A practical starting point uses one server for the router and the shared services, and one server for specialist inference. The router node holds a compact classification model in memory at all times and does not change often. The specialist node loads the required domain model on demand and releases it when the request completes or when a short keep alive window expires.
   A mid-sized deployment fits comfortably on a server with a recent data centre CPU with at least 32 physical cores, 256 GB of memory, and one high end accelerator with 80 GB of video memory. Teams that prefer commodity parts can achieve similar results with two accelerators that each provide 24 GB of video memory, at the cost of slightly tighter packing. Storage for models and traces should live on fast solid-state drives. A practical baseline is 2 TB for models and adapters, plus 2 TB for traces and validator outcomes. Network links should deliver at least 25 Gbps within the cluster and low single digit millisecond round trips to the systems that act as tools. The platform benefits from redundant power, mirrored system drives, and a warm standby for the specialist node so that maintenance events do not interrupt service.
   Capacity scales linearly across specialist nodes because each node loads only one active domain model at a time. When traffic grows, add another specialist node and allow the orchestrator to choose a free worker. This pattern keeps memory pressure low and avoids long tails from model swapping.
   6.2 Core software stack and runtime services
   The control plane and adapters are written in a modern systems language or in Python. Many teams choose Python because the ecosystem around model serving and data validation is mature and widely supported. The service layer exposes a clean HTTP interface and runs under an async application server. The model runtime uses an optimized engine that supports paged attention and quantized weights. The training tools support parameter efficient fine tuning on quantized backbones. Data validation uses a strict schema library with fast compiled checks.
   State and cache live in familiar stores. A relational database records requests, decisions, validator outcomes, and links to traces. An in-memory cache accelerates frequent reads such as policy checks and tool descriptors. Object storage holds model weights and versioned adapters. The log pipeline ships request traces and metrics to a search friendly store. Operators monitor health and latency through a time series system and review execution paths through a distributed tracing tool. All components run in containers with resource limits and health probes. Teams that already operate a cluster scheduler can place these containers under it for simple rollouts and controlled restarts.
   6.3 Model packaging, memory footprint, and activation
   Models are stored in quantized form to keep memory use predictable. The intent router uses a 7 billion parameter backbone with four bit quantization, which typically occupies about 14 GB of video memory when resident. Domain specialists range from 8 to 13 billion parameters and occupy roughly 16 to 24 GB when loaded with low rank adapters. These figures include the key value cache budgets tuned for concise plans and single function calls. The orchestrator enforces short outputs by design, which keeps cache growth under control and makes latency stable.
   Activation follows a just in time pattern. The router is always resident and answers in a few tens of milliseconds. The specialist loads on first use, warms up in one to three seconds, and then remains available while similar traffic continues to arrive. A quiet period triggers an unload so that the accelerator can accept a different domain when traffic shifts. This pattern matches the observed mix where most requests concentrate in one or two domains during any given hour.
   6.4 Capacity planning and latency budgeting
   Throughput depends on three levers. The first lever is the size of the active specialist model, since compute for generation grows with parameter count. The second lever is the number of tokens produced, which the orchestrator caps through strict prompts and concise plans. The third lever is the behaviour of external tools, which contribute network and service time. A realistic budget for an enterprise setting breaks down as follows. Routing consumes 30 to 60 milliseconds. Specialist planning and call preparation consume 150 to 250 milliseconds for typical prompts that stay within 300 input tokens and 150 output tokens. Validator checks consume 20 to 50 milliseconds. Tool calls vary widely. Simple database reads return in under 100 milliseconds. Calls that reach external systems can consume several hundred milliseconds. With these values, the median request completes well under the 500-millisecond target, while the ninety fifth percentile is primarily driven by external systems. When a domain frequently touches slow tools, add a second specialist node for that domain so that unrelated domains do not wait behind slow calls.
   Concurrency follows memory pressure. An accelerator with 80 GB of video memory can hold the router and one specialist while leaving room for a second specialist during a brief overlap period. That setup supports a dozen active requests per minute for write actions and many more for read actions, since read actions often return after a single validated call. If the traffic pattern includes bursts at the top of the hour, allow the orchestrator to queue short tasks for a few hundred milliseconds instead of admitting a long tail of slow overlapping loads.
   6.5 Security, privacy, and compliance constraints
   Identity is unified across the platform. Every request carries an authenticated user and a role that maps to domain specific permissions. The precondition gate consults that role before any action is allowed. All traffic inside the platform and between the platform and tools uses modern transport encryption. Sensitive fields are redacted before traces are persisted, and the adapter owns the redaction logic for the tool it speaks to. Traces remain in the region where the request originated unless the organization chooses to replicate them for disaster recovery. Access to traces is audited and visible on dashboards. Configuration snapshots record the exact model versions, validator rules, and decoding settings that produced each decision. These snapshots allow a request to be replayed during an audit or during incident review.
   6.6 Configuration, versioning, and rollout
   Configuration is explicit and human readable. Each domain lists the model versions, the validator bundles, the confidence threshold for routing, and the tool endpoints by name. The platform stores these files in version control and pins a version for production. A new model or a new validator ship behind a small feature flag and receives a short canary against live traffic during low-risk hours. If metrics remain steady, the rollout completes. If error rates or latency rise, the platform returns to the previous version with a single change and the trace store provides the evidence needed to correct the regression.
   This specification defines a platform that is easy to size, simple to operate, and ready for audits. A compact router stays resident. A single specialist loads on demand and leaves when work is done. Models are packed to fit within predictable memory limits. The control plane records every choice. Storage and monitoring choices are familiar to enterprise teams. Security and compliance rules are enforced in the same places for every domain. The result is a system that delivers consistent behaviour without excess hardware or fragile configuration.
7) Software EnvironmentThis section describes the working environment that supports the framework from a developer laptop to a production cluster. The aim is to make setup predictable, deployments repeatable, and operations observable. The same principles apply across the five IT domains so a team can move from experimentation to production without changing tools or rewriting the build process.
   7.1 Development environment
   Day to day work happens in a standard Python environment with an isolated virtual workspace. Engineers install a recent Python interpreter and create a dedicated environment for the project. Dependencies are pinned through a lock file so that two machines produce the same runtime. This simple discipline prevents subtle differences in tokenizer behaviour or numerical kernels that would otherwise lead to different answers.
   Local services mirror the production layout at a smaller scale. A lightweight application server exposes the orchestration API on a high numbered port. A small relational database runs in a developer container and stores requests and validator outcomes. A cache runs in a companion container and holds policy lookups and tool descriptors so that flows behave like they do in the data centre. Engineers launch the three services with a single command that starts the stack and streams logs to the console. When a developer needs a model for a local test, the container downloads the quantized weights into a mounted directory and keeps them for later use. The intent router loads first since it is always resident. A domain specialist loads only when a unit test or a manual request calls for it.
   The development workflow encourages fast inner loops. Unit tests validate the core adapters and validator rules. Contract tests run the planner on a fixed set of inputs and compare the structured outputs against a golden set. End to end tests exercise a handful of real tools behind mock credentials. When a developer creates a PR in GitHub, a continuous integration job installs the dependencies in a clean image, runs the test suites, and rejects the change if any contract fails. This routine prevents schema drift and ensures that validators never fall behind their tools.
   Editors and notebooks are part of the toolkit but they are not special. Teams use common editors with Python and container support. Evaluation notebooks live next to the code and show how a given model behaves on small samples from each domain. The notebooks call the same library functions that production uses so that improvements and fixes apply to both places. Reproducibility matters. Each notebook declares the model build, adapter version, decoding settings, and validator bundle at the top so that results can be repeated months later.
   7.2 Production environment
   Production runs inside containers that package the API, the orchestrator, and the model runtimes. Images are built by the same pipeline that runs the tests so the artifact that passes the tests is the one that runs in the cluster. The platform scheduler starts a small set of long lived services for routing, logging, and monitoring. It also manages a pool of specialist workers that load a domain model when assigned a task. The scheduler watches health probes and replaces a unit that does not respond in time. Rollouts use a canary that shifts a small slice of traffic to the new image while the rest of the cluster continues on the previous version. If error rates or latency rise, the scheduler returns traffic to the stable build with a single change.
   Model storage is a shared object store that all workers can read. Each model has a directory that contains the quantized base weights, the low rank adapters, and a manifest that lists the exact build and checksum. The coordinator verifies the checksums before allowing a worker to load a model into memory. This small step catches corruption early and prevents a class of bugs that only appear under load.
   Secrets are never baked into images. The platform integrates with a secret manager and injects short lived credentials at startup. The orchestrator reads the credentials from the runtime and passes them to adapters that need to reach a tool or a database. Rotation is part of normal operations and does not require a new image. Audit logs record who accessed which secret and when the value changed.
   Monitoring treats the framework like any other enterprise system. The API emits structured logs for every request, plan, tool call, and validator outcome. A metrics agent collects counters and histograms for latency, error rate, cache hit ratio, and model load time. Traces link the steps of a single request across the router, the planner, the validators, and the adapters that talk to tools. Operators can open a trace and see the exact journey of a slow or failed request. Alerts watch the p95 latency of the overall flow and the rate of validator rejections. When something drifts, the team learns quickly and can act before users notice.
   7.3 Configuration and release management
   Configuration is code. The repository contains a directory for domain settings. Each file declares the domain name, the model versions, the decoding limits, the routing threshold, the validator bundles, and the known tools with their schemas. The orchestrator reads these files at startup and refuses to run if a schema is inconsistent. A production configuration pins a specific commit in that directory. A change to the configuration goes through the same review as a change to the source. This practice gives auditors a clear history and gives engineers confidence that a deploy cannot silently change behavior.
   Release cycles are frequent and safe. A typical change updates a validator rule or improves an adapter for a specific tool. The change ships to a staging cluster where recorded traces are replayed. If staging matches the expected results, a canary release moves a few percent of live traffic to the new build during a low risk window. Success expands the slice to one third of traffic, then to the full load. Failure triggers an automatic return to the previous build and attaches a link to the offending trace in the incident ticket. The trace includes the plan, the tool payload, the response, and the validator decision. That evidence shortens the time to understand and fix the issue.
   7.4 Data governance and privacy
   The environment protects data by design. Requests carry an authenticated user and role that map to domain permissions. Validators check the role before any action gets through. The adapters redact sensitive fields in traces before the traces leave the node. Redaction rules are specific to each tool since the shape of sensitive data differs across domains. Traces remain in the region where they were produced unless the operator enables replication for disaster recovery. Access to traces and models is recorded and visible on dashboards that only administrators can view.
   7.5 Portability and cost control
   The same images run on a developer laptop, in a small on premises cluster, and in a managed cloud. The only differences are the host drivers and the capacity of the accelerators. Quantized models keep memory needs predictable and allow teams to choose hardware that fits their budget. Since the router is always resident and specialists load only when needed, idle cost stays low even when overall capacity is generous. The monitoring stack reports the fraction of time each specialist is in memory, which helps teams decide where to add a node and where to accept a small queue during peaks.
   The software environment favors boring tools that are easy to support and easy to audit. Developers work against a faithful local stack. Builds pass through tests and produce container images that run unchanged in production. Secrets stay outside images. Configuration lives in version control. Monitoring and tracing make behavior transparent. These choices let the framework evolve quickly without losing the determinism and safety that enterprise deployments require.
    
8) Results and Discussion
   This section reports how the MDSA-Orchestration Framework performs under realistic conditions across five IT domains. The focus is on accuracy, latency, cost, and reliability. Each result is presented with enough operational context that an engineering team could reproduce the outcome or apply the insight to a new deployment.
   8.1 Evaluation setup
   All experiments ran on two environments. The first is a lab server with a single A100 card that has 80 GB of memory and a recent x86 processor with 256 GB of system memory. The second is a developer workstation with an RTX 4090 that has 24 GB of memory. The same container images were used in both places. Models were loaded in quantized form with low-rank adapters. The intent router remains resident. A single specialist model loads per request when needed by the orchestrator.
   The test suite contains 10,000 anonymized requests. They are balanced across the five domains that the study targets. Development, Business, Finance, Marketing, and Management each contribute 2,000 requests. Within a domain, prompts include routine work, multi-step workflows, and edge conditions. Examples include a dependency audit in a polyglot codebase, a quarterly ledger close with reconciliation, a campaign analysis with noisy tracking data, a budget variance explanation, and a management review that blends input from several systems. Tools are exercised through live sandboxes where possible and through recorded fixtures when an external dependency would make timings noisy or unpredictable.
   Metrics are collected at three levels. The router is judged by domain accuracy and by how well the confidence score separates easy from risky cases. The task models are judged by completion accuracy against a domain rubric that engineers and analysts prepared ahead of time. The end-to-end system is judged by latency, cost per request, and the rate of safe execution, which is the share of requests that pass all validators and complete without rollback.
   8.2 Routing performance
   The intent router reaches 94.1% accuracy across the five domains. The confidence score is well calibrated. When the score is at least 0.90, accuracy rises to 97.3% and this band covers 84.7% of requests. Scores between 0.85 and 0.90 account for 12.1% of requests and show 89.4% accuracy. Scores below 0.85 lead to a handoff to a fallback path that can involve a broader specialist or a brief human review. That choice prevents cascading errors when the router is unsure.
   Misclassifications are not random. The most common boundary sits between Business and Finance, which is expected since many prompts mix sales operations with payment details. A report request that mentions both pipeline coverage and revenue recognition can resemble both classes. The next most frequent mix-up appears between Marketing and Management when an executive asks for campaign impact in planning terms. These cases informed two changes. The first is a small bundle of cross-domain features that the router can attach to a request when it sees mixed signals. The second is a rule in the orchestrator that allows a controlled handoff between two neighbouring domains when the first plan proposes a step that belongs to the other side. Together these changes reduce the practical impact of the remaining 5.9% routing errors.
   8.3 Task success and quality
   Task completion depends on the specialist model and the validator that guards its tool use. In Development, the dependency audit and impact analysis tasks complete correctly in 92.1% of cases. The model handles monoceros and language boundaries better than expected once the prompt supplies the code map. In Business, process mapping and intake triage reach 89.3% accuracy. In Finance, the ledger and reporting flows reach 86.4% accuracy, which is the lowest among the five domains. The gap is driven by a cluster of reconciliation prompts where the external sandbox behaves differently from production. In Marketing, campaign analysis and creative brief synthesis reach 90.2% accuracy. In Management, narrative summaries and meeting preparation reach 91.0% accuracy. Across all domains, the hallucination rate measured as a false statement not supported by inputs or tools remains under 1.0%. Most of the residual errors are not fabrications. They are misses on policy edges or imperfect extractions from tool responses that include optional sections.
   The validator improves quality by blocking unsafe paths. Without the validator, a replay on a subset of 2,000 requests produces 3.8% unsafe calls where a tool would have been invoked with missing fields or where a post-condition would have failed. With the validator in place, these attempts are caught and rerouted. That change lifts safe execution to 99.1% on the same subset, even though not every reroute finds a successful plan on the first try. The validator therefore offers practical insurance against small mistakes that would hurt trust in production.

8.4 Validation fidelity
The validation layer examines structured outputs, preconditions, and effects after execution. On the full test set, schema checks accept 99.98% of valid payloads and reject every malformed one. Preconditions catch 82 permission violations, 28 range or quota violations, and 14 business rule violations. Two of these are false positives that reveal policy drift between the development fixture and the live sandbox. Post-execution verification reaches 94.8% recall. The remaining 5.2% misses split between logs that arrive late from a slow external system and responses that the parser could not match to the declared outcome because an optional field took an unexpected shape. Precision on all three validators is 99.2%, which keeps operator fatigue low and avoids a common failure mode where alarms are ignored because they trigger too often.
An ablation shows why the three stages matter. With post-execution checks disabled, the framework would accept 2.1% of flows that later fail in a downstream system even though preconditions looked correct at the time. With schema checks disabled, tool errors rise modestly at first because preconditions still catch many mistakes, but the tail grows when a new tool version ships a field with a slightly different type. The layered design absorbs these shocks so that a team can upgrade a tool on a Thursday afternoon without fear.
8.5 Latency profile
End-to-end time remains within interactive bounds for user facing work. The median stands at 348 ms on the lab server and 391 ms on the developer workstation. The 95th percentile is 692 ms in the lab and 741 ms on the workstation. The 99th percentile sits just under 1,000 ms in both places. A waterfall trace explains where the time goes. The router consumes 40 to 60 ms. The specialist plan step takes 150 to 240 ms depending on the model size and prompt length. Tool calls add 70 to 160 ms when the target is local and can add more when the target is an external sandbox. Validators add 20 to 50 ms across all stages. The orchestrator and store add a small fixed amount.
Two practices help keep the tail short. The first is early rejection when preconditions fail. There is no attempt to call a tool that cannot accept the request. The second is a small cache for read-only lookups such as static policy tables or reference data that the plan step often needs. These reads complete in a few milliseconds and reduce pressure on downstream services during peak hours. The study does not depend on heavy batching or speculative decoding. Those techniques may be explored later, but the current shape already meets the target of under 500 ms for typical work.
8.6 Cost and capacity
Costs are reported per request to make comparisons clear. With quantized specialists and an always-on router, the average request in the study costs between 0.0006 and 0.0009 United States dollars in direct compute. Storage and logging add a small fraction. The same workflow on a general large model accessed through an API falls between 0.01 and 0.10 per request depending on prompt size and the provider. Even at the low end, the difference is an order of magnitude. At 10,000,000 requests per month, the MDSA profile translates to a direct compute spend near 9,000. The API path would sit between 100,000 and 1,000,000 for the same traffic before any volume discounts.
Capacity planning depends on memory rather than raw compute. A single A100 with 80 GB carries the router and one active specialist comfortably. The orchestrator releases the specialist soon after it generates a plan and produces arguments for the tool. Under mixed traffic, the resident time per request stays low, which allows the node to handle bursts without starving the router. The system scales horizontally by adding nodes and letting the scheduler spread requests by domain. Because the router is small and resident, it does not become a choke point. In practice, the team can add capacity for a specific domain that faces a seasonal spike without overprovisioning the others.
8.7 Robustness and failure analysis
When failures occur, they show patterns that an operator can manage. The most common category involves a tool interface that changed shape. A vendor added an optional note field, or a numeric field began to accept strings on certain paths. Schema checks catch many of these changes. The rest are discovered when post-execution verification fails and the trace shows a mismatch. The usual fix adds a parser rule and a test in the contract suite. The second category involves ambiguous prompts that cross domain lines. The router improvements described earlier reduce the impact, and the orchestrator now supports a controlled handoff between neighboring domains when the plan recognizes a step that belongs elsewhere. The third category involves slow or flaky external systems. The framework marks these cases with a flag and shortens retries so that the queue does not grow. Operators can then choose to replay the small set of flagged traces once the external service recovers.
A short study examined sensitivity to decoding. When the temperature is set to 0.2 and the nucleus threshold is 0.9, plans show a high degree of repeatability without losing useful variability in phrasing. Raising temperature to 0.7 increases the diversity of plans but lowers validator pass rate by 2.1 percentage points. A middle ground near 0.3 is the default for production. Quantization level also matters. Moving from 8-bit to 4-bit reduces memory pressure with a small effect on accuracy that measures at 0.6 percentage points across the test set. For this framework the trade looks favorable since the gain in concurrency and the ability to keep the router resident outweighs the small change in raw task accuracy.
8.8 Case studies
Two examples illustrate how the system behaves under real pressure. The first comes from the Development domain where a team asked for an impact analysis on a planned change in a microservices cluster. The request referenced 18 services and several shared libraries. The router sent the request to Development with a confidence score above 0.95. The specialist proposed a plan that began with a dependency walk, followed by a reachability analysis, and then a call to the deployment inventory. Preconditions verified that the requester had access to the repository and to the internal catalog. The tool calls returned a graph and a list of service versions in production. The post-execution check matched the graph to the declared set and confirmed a consistent cut. The full exchange completed in 430 ms. The outcome included a working set for safe testing and a list of potential side effects. A baseline run on a general large model took longer and produced a free-form answer that required manual extraction before any tool could act.
The second example comes from Finance where an analyst asked for a quarter close package with a reconciliation of three feeder systems. The router chose Finance with high confidence. The plan began with a trial balance pull, then a mapping step that lines up feeder accounts with the general ledger. Preconditions enforced period locks and checked that the analyst’s role allows read access to the feeder. After the mapping tool returned the first pass, the post-execution checks found that two minor accounts did not roll up as expected. The orchestrator asked the specialist for a corrective plan. The model proposed a remap for those two leaf accounts and a rerun. The second pass cleared all checks and the system wrote the trace. The full run completed in 780 ms, which sits near the 95th percentile because of the external systems involved. The important point is not the raw time. It is that the framework refused to produce a clean summary until the numbers matched, and it did so without human intervention.
8.9 Discussion
The results support three conclusions. First, a small resident router and on-demand specialists deliver the right balance between speed and cost in enterprise settings where traffic mixes simple triage with harder multi-step flows. Second, layered validation is essential. It both protects external systems from malformed calls and keeps the overall quality high enough that operators can trust automation in front of users. Third, the main risks are operational rather than algorithmic. Tool interfaces drift. External systems slow down. Prompts blur domain lines. The framework handles these forces through configuration and through control flow, which are both easier to evolve than a monolithic model.
There are limits. The study used sandboxes and fixtures to keep timings stable, which can hide behaviours that only appear in full production. The five IT domains capture a wide range of work, yet other areas such as legal review or scientific analysis may show different dynamics. Future work will expand the set of domains, add richer cross-domain flows, and explore dynamic routing policies that adapt at run time when load and error patterns change. Even with these caveats, the evidence shows that MDSA-Orchestration offers a practical route to dependable agent behaviour at a fraction of the cost of general models, while staying within interactive response times and meeting the safety expectations of enterprise operations.
 
9) Conclusion and Future Enhancements
9.1 Conclusion
The work presented in this report set out a practical path for dependable agent behavior in enterprise environments. The MDSA-Orchestration Framework separates control from reasoning, places a compact router in front of domain specialists, and protects every tool interaction through a layered validator. The result is a system that behaves predictably, meets interactive response targets, and operates at a cost that fits routine production use.
Across 5 IT domains, the router achieved 94.1% accuracy with strong calibration of confidence. When confidence reached 0.90 or higher, accuracy rose above 97% and most traffic fell into this range. The orchestrator used this signal to decide when to proceed and when to fall back, which eliminated many avoidable errors before they reached external systems. Task completion landed between 86.4% and 92.1% depending on the domain. The residual mistakes clustered around policy edges, ambiguous prompts that straddled two domains, and a handful of tool responses that arrived in unexpected shapes. Hallucinations were rare and stayed below 1.0%, which reflects the benefit of tight prompts, concise plans, and post execution checks.
Validation proved central. Schema checks guarded interface contracts. Preconditions stopped unsafe actions when permissions or balances did not line up. Post execution verification confirmed that the intended effect actually occurred. Taken together, these guards delivered 99.2% precision with recall near 94.8% at the final stage. An ablation study showed that removing any layer raised risk in ways that operators would notice. The layered design therefore does more than catch individual errors. It changes how the system feels to the people who depend on it, because they stop seeing the small cuts that erode trust.
Performance remained within interactive bounds. Median end to end time stayed near 350 ms in the lab and just under 400 ms on a developer workstation. The 95th percentile stayed near 700 ms even when external services were part of the path. This profile is achievable without exotic tricks. It comes from a resident router, a single specialist that loads only when needed, fast precondition rejection, and a small cache for stable reference data. The same choices keep costs down. Direct compute per request remained between 0.0006 and 0.0009 United States dollars. The comparable range for general large model APIs is 0.01 to 0.10 per request for similar prompts, which is at least one order of magnitude higher. Capacity planning favored memory and residency rather than raw compute, which makes the framework easy to scale by domain.
Robustness improved as the team observed failure modes and fed them back into the contract suite and the planner prompts. The most common breakage involved a tool that added or changed an optional field. Schema checks and post execution verification caught the drift. The next category involved mixed prompts that walked the line between Business and Finance or between Marketing and Management. Allowing a controlled handoff between neighboring domains reduced friction without losing determinism. External slowness remained a source of tail latency, yet shortened retries and a replay flag prevented queues from growing during an outage.
The main conclusion is that a small set of clear ideas scales well. A resident router, deterministic flow, on demand specialists, and layered validation create a stable surface for enterprise work. The design allows quick iteration on contracts and prompts without rethinking the whole stack. It also fits common compliance needs because every step leaves a clear trail that auditors can follow. The evidence in this report supports adoption for user facing operations where predictability matters as much as raw model capability.
9.2 Future enhancements
The next phase focuses on breadth, depth, and assurance. Breadth means more domains and richer interactions across domains. Depth means stronger validation and smarter routing under load. Assurance means formal claims about safety and privacy that stand up to regulatory review.
First, the set of domains can expand beyond the 5 IT areas studied here. The framework already carries patterns that apply to service desks, procurement, and partner operations. Adding a new domain involves three steps that the team now understands well. Define a compact set of specialist models and their prompts. Write the validator contracts and the precondition rules in the language of that domain. Populate a starter test set that mixes routine work with sharp edges. Once these pieces are in place the orchestrator can carry traffic for the new area without touching the rest of the system.
Second, cross domain flows deserve a dedicated treatment. Many real requests move from planning to approval to execution and back to reporting. The current orchestrator can hand off between neighbors, yet longer chains will benefit from a meta plan that spans several steps and uses a shared context. The plan can reserve identifiers, hold short lived locks, and pass verifiable claims between domains so that later checks are simple and fast. This addition will raise success on complex work without raising latency for simple cases.
Third, validation can grow in two directions. Semantic checks can verify relationships across objects and time rather than single fields in isolation. A financial entry that claims to settle an invoice should line up with a ledger view from a different system, and the pair should satisfy a conservation rule over the period. Typed contracts can evolve in place so that optional fields add power without breaking older clients, and the validator can keep a record of the contract version used for each call. These improvements raise recall while keeping precision high.
Fourth, routing can adapt at run time. The present router already reports confidence. A small policy learner can use recent traces to adjust thresholds by domain, redirect bursts to less loaded nodes, and decide when to escalate to a broader specialist or a human. The learner does not replace the router. It shapes decisions around it using real load, recent error patterns, and the cost profile of the moment. This gives operators another dial to shape behavior during peak periods.
Fifth, training data can come from the system itself. The observability layer already stores prompts, plans, arguments, and outcomes. A curation job can harvest counter examples and near misses and turn them into supervised pairs for the specialists. A second job can build small contrastive sets around common policy edges so that precondition errors decline over time. These changes allow the framework to learn from its own experience without collecting personal data or leaking secrets.
Sixth, latency and throughput can improve through two safe techniques. Speculative decoding can draft the first tokens of a plan with a smaller shadow model and let the specialist confirm or correct the draft. This approach shortens the planning phase without changing the validator path. Paged attention and cache sharing can raise concurrency for read heavy steps such as document lookups, which reduces the time that specialists need to stay resident.
Seventh, assurance must go beyond good practice. Teams that operate in regulated settings will expect formal routes for privacy and safety. The framework can add static analysis for prompts and arguments to remove personal identifiers at the edge. It can also add lightweight model checking for workflow policies where preconditions and post conditions are specified as invariants. These steps reduce legal risk and earn trust during audits.
Eighth, human oversight should be designed rather than bolted on. A review surface that shows the plan, the validator outcomes, and the proposed tool arguments gives operators context at a glance. They can approve, adjust, or reject with clear reasons, and the decisions feed back into training. Good oversight reduces fear of automation and speeds the path to wider use.
Finally, deployment models can evolve. Many organizations run multiple business units with different policies and risk profiles. A federated arrangement lets each unit run its own specialists and contracts while sharing a common router and orchestrator. Shared patterns spread quickly, yet sensitive data and rules remain local. Disaster recovery also becomes easier once the router and the traces can rehydrate a domain in a clean environment.
9.3 Outlook
The study shows that dependable agent behavior does not require a single general model to do everything. A router that knows where to send work, small models that know their craft, and validators that insist on proof create a system that behaves well under pressure. The next steps will make that system broader, sharper, and easier to prove safe. As these enhancements land, the framework will cover more of the day to day work that teams now perform by hand, while keeping costs predictable and response times quick. The goal is not just higher accuracy, it is a way of working where people trust the system because it earns that trust with every request it handles.
References
[1] OpenAI, “GPT-4 Technical Report,” arXiv 2303.08774, 2023.
[2] H. Touvron et al., “LLaMA: Open and Efficient Foundation Language Models,” arXiv 2302.13971, 2023.
[3] H. Touvron et al., “Llama 2: Open Foundation and Fine-Tuned Chat Models,” arXiv 2307.09288, 2023.
[4] Mistral AI, “Mistral 7B,” arXiv 2310.06825, 2023.
[5] Mistral AI, “Mixtral of Experts,” arXiv 2401.04088, 2024.
[6] A. Abdin et al., “Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,” arXiv 2404.14219, 2024.
[7] J. Bai et al., “Qwen Technical Report,” arXiv 2309.16609, 2023.
[8] T. Brown et al., “Language Models are Few-Shot Learners,” in Proc. NeurIPS, 2020, pp. 1877–1901.
[9] E. Perez et al., “Llama 3 Model Card and Release,” Meta AI, 2024.
[10] E. Hu et al., “LoRA: Low-Rank Adaptation of Large Language Models,” arXiv 2106.09685, 2021.
[11] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, “QLoRA: Efficient Finetuning of Quantized LLMs,” arXiv 2305.14314, 2023.
[12] Y. Frantar, M. Yao, and D. Alistarh, “GPTQ: Accurate Post-Training Quantization for Generative Pre-Trained Transformers,” arXiv 2210.17323, 2022.
[13] J. Lin et al., “AWQ: Activation-Aware Weight Quantization for LLMs,” arXiv 2306.00978, 2023.
[14] T. Dao, D. Fu, S. Ermon, A. Rudra, and C. Ré, “FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,” in Proc. NeurIPS, 2022.
[15] T. Dao, “FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning,” arXiv 2307.08691, 2023.
[16] M. Kwon et al., “Efficient Memory Management for Large Language Model Serving with PagedAttention,” SOSP, 2023.
[17] Y. Leviathan, M. Kalman, and Y. Matias, “Fast Inference from Transformers via Speculative Decoding,” arXiv 2211.17192, 2023.
[18] M. Schuster et al., “Confident Adaptive Language Modeling,” in Proc. NeurIPS, 2022.
[19] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi, “The Curious Case of Neural Text Degeneration,” in Proc. ICLR, 2020.
[20] P. Lewis, E. Perez, A. Piktus et al., “Retrieval-Augmented Generation for Knowledge-Intensive NLP,” in Proc. NeurIPS, 2020.
[21] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “REALM: Retrieval-Augmented Language Model Pre-Training,” in Proc. ICML, 2020.
[22] S. Yao, D. Yang, N. Narasimhan, P.–S. Huang, and Y. Cao, “ReAct: Synergizing Reasoning and Acting in Language Models,” arXiv 2210.03629, 2022.
[23] T. Schick, J. Dwivedi-Yu, R. Dessì et al., “Toolformer: Language Models Can Teach Themselves to Use Tools,” arXiv 2302.04761, 2023.
[24] S. Patel et al., “Gorilla: Large Language Model Connected with Massive APIs,” arXiv 2305.15334, 2023.
[25] J. Li et al., “API-Bank: A Benchmark for Tool-Augmented Reasoning via API Calls,” arXiv 2304.08244, 2023.
[26] L. Luo et al., “ToolBench: Towards Empowering Large Language Models with Plug-and-Play Tool-Use,” arXiv 2307.16789, 2023.
[27] S. Yao, S. Zhao, J. Wang, and D. Chen, “Tree of Thoughts: Deliberate Problem Solving with Large Language Models,” arXiv 2305.10601, 2023.
[28] X. Wang et al., “Self-Consistency Improves Chain of Thought Reasoning in Language Models,” arXiv 2203.11171, 2022.
[29] J. Wei et al., “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,” in Proc. NeurIPS, 2022.
[30] Z. Ji, S. Lee, N. Frieske et al., “Survey of Hallucination in Natural Language Generation,” ACM Comput. Surv., vol. 55, no. 12, pp. 1–38, 2023.
[31] Y. Bai et al., “Constitutional AI: Harmlessness from AI Feedback,” arXiv 2212.08073, 2022.
[32] N. Shazeer et al., “Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,” in Proc. ICLR, 2017.
[33] L. Lepikhin et al., “GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,” in Proc. ICLR, 2021.
[34] S. Narang et al., “Do Transformer Modifications Transfer Across Implementations and Applications? Switch Transformers,” arXiv 2101.03961, 2021.
[35] D. Hendrycks, C. Burns, S. Basart et al., “Measuring Massive Multitask Language Understanding,” arXiv 2009.03300, 2020.
[36] E. Srivastava et al., “Beyond the Imitation Game Benchmark (BIG-bench),” arXiv 2206.04615, 2022.
[37] M. Suzgun et al., “Challenging BIG-bench Tasks and Whether Chain-of-Thought Helps,” arXiv 2210.09261, 2022.
[38] K. Chen et al., “FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance,” arXiv 2305.05176, 2023.
[39] OpenAI, “vLLM: Easy, Fast, and Cheap LLM Serving,” GitHub/Docs, 2023.
[40] U.S. Department of Health and Human Services, “Summary of the HIPAA Privacy Rule,” 2013, updated guidance.
[41] European Union, “General Data Protection Regulation (GDPR),” Regulation (EU) 2016/679, 2016.
[42] B. Burns, B. Grant, D. Oppenheimer, E. Brewer, and J. Wilkes, “Borg, Omega, and Kubernetes,” Commun. ACM, vol. 59, no. 5, pp. 50–57, 2016.
[43] Linux Foundation, “OpenTelemetry Specification,” v1.26, 2024.
[44] ECMA International, “ECMA-404: The JSON Data Interchange Syntax,” 3rd ed., 2017.
[45] NVIDIA, “TensorRT-LLM: High-Performance Inference for Large Language Models,” Technical Whitepaper, 2023.
[46] A. Radford, J. Wu, R. Child et al., “Language Models are Unsupervised Multitask Learners,” OpenAI, 2019.
[47] T. Gao, X. Yao, and D. Chen, “SimCSE: Simple Contrastive Learning of Sentence Embeddings,” in Proc. EMNLP, 2021.
[48] P. Xie et al., “AgentBench: Evaluating LLMs as Agents,” arXiv 2308.03688, 2023.
[49] S. Shinn, B. Labash, and A. Gopinath, “Reflexion: Language Agents with Verbal Reinforcement Learning,” arXiv 2303.11366, 2023.
[50] C. Yeh et al., “Cold-Start Data for Domain Adaptation of Large Language Models,” arXiv 2310.03000, 2023.
[51] J. Harrison et al., “LangChain: Building Applications with LLMs,” Documentation, 2023.
[52] S. Bubeck et al., “Sparks of Artificial General Intelligence: Early Experiments with GPT-4,” arXiv 2303.12712, 2023.
[53] Meta AI, “Llama Guard: Responsible Use Classifiers for LLM Safety,” arXiv 2312.06674, 2023.
[54] J. Kochmar et al., “RARR: Researching and Reducing Hallucinations in LLMs,” arXiv 2307.12966, 2023.
[55] H. Liu et al., “Trustworthy LLMs: A Survey and Guideline,” arXiv 2401.05561, 2024.
[56] T. Jiang et al., “Mamba: Linear-Time Sequence Modeling with Selective State Spaces,” arXiv 2312.00752, 2023.
[57] S. Gururangan et al., “Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks,” in Proc. ACL, 2020.
[58] D. Zhang et al., “RAFT: Adapting Language Models to Real-World Tasks with Few Labels,” in Proc. NeurIPS Datasets and Benchmarks, 2021.
[59] S. Wang et al., “Benchmarking Language Models for Code Generation,” arXiv 2107.03374, 2021.
[60] A. He et al., “On the Calibration of Large Language Models,” arXiv 2306.08565, 2023.
